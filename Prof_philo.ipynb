{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0d8e77e-2bd7-47ba-91b0-fa428f6c2936",
   "metadata": {},
   "source": [
    "# Jouons au professeur de Philosophie\n",
    "\n",
    "<img src=\"images/prof.png\" width=\"150\" alt=\"Prof looking at a electronic brain\" style=\"float: left; margin-right: 15px; margin-bottom: 10px;\">  Dans cette partie pour nous initier à l'Agentique AI, et voir ce que c'est, nous allons prendre le rôle d'un professeur de philosophie qui doit rédiger un sujet, il le donnera à ses étudiants. Il corrigera les réponses et classera les élèves. Dans notre cas, tous ces acteurs seront mis en oeuvre par une LLM.\n",
    "\n",
    "Nous utiliserons plusieurs LLM, la pluspart gratuite, mais pour quelques euro vous pourrez accéder à d'autres services, mais ce n'est pas essentiel pour ces exercices. Nous utiliserons:\n",
    "\n",
    "* Plusieurs LLM mis à notre disposition par l'université de Rennes 1\n",
    "* Le LLM de Google\n",
    "* Un modèle tournant sur votre propre machine\n",
    "* et si vous le souhaitez OpenAI et Antropic (payant: ~5€)\n",
    "\n",
    "# Mise en oeuvre\n",
    "\n",
    "## API\n",
    "\n",
    "Pour communiquer avec un LLM, nous allons utiliser une API REST, et pour pouvoir nous identifier, nous devons devoir créer un jeton (token), sur son site. Notre LLN de référence est hébergée à l'Universite de Rennes. Vous pouvez vous y connecter avec votre login IMT Atlantique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e896d1be-a7a0-4888-9c96-02582f77f5ee",
   "metadata": {},
   "source": [
    "### LLMs de l'Université de Rennes \n",
    "\n",
    "Pour vous connecter aux machines de l'Université de Rennes, cliquez sur ce lien: https://ragarenn.eskemm-numerique.fr/sso/ch@t/app/auth\n",
    "\n",
    "* Selectionnez IMT Atlantique\n",
    "* Logguez vous\n",
    "\n",
    "<img src=\"images/UR-param.png\" width=\"100\" alt=\"Prof looking at a electronic brain\" style=\"float: left; margin-right: 15px; margin-bottom: 10px;\">  En haut, à droite, vous avez accès à votre environnement. Cliquez sur **Paramètres**; sur **Compte** et sur **Clés d'API**.\n",
    "\n",
    "* Créez votre clé d'API et copiez là.\n",
    "\n",
    "* Editez le fichier .env qui se trouve dans ce répertoire et ajoutez la ligne **RENNES_API_KEY==**<<clé copiée>>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ace219-9d5e-4b0b-be1d-48b14b180ce6",
   "metadata": {},
   "source": [
    "### Google Gemini \n",
    "\n",
    "Google permet d'accèder gratuitement à son LLM, nous devons également récupérer une clé d'API.\n",
    "\n",
    "* Allez sur le site https://aistudio.google.com/apikey (connectez vous à votre compte Google)\n",
    "* Creez une clé d'API et copiez là.\n",
    "* Ajouter une ligne dans le fichier .env **GOOGLE_API_KEY==**<<clé copiée>>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34497c18-5257-4226-9994-c3a6cf4a5ce7",
   "metadata": {},
   "source": [
    "### Ollama\n",
    "\n",
    "Ollama permet de faire tourner localement un LLM sur votre machine. Bien sûr, ce sera moins performant que sur un serveur spécialisé, mais celà pourra sufir dans certains cas, ou celà permettra de comparer différents modèles.\n",
    "\n",
    "* téléchargez l'exécutable correspondant à votre système sur https://ollama.com/\n",
    "* Installez le programme\n",
    "\n",
    "Ollama fonctionne par ligne de commande, tapez depuis un shell:\n",
    "\n",
    "* `ollama pull gemma3:1b` pour installer un premier modèle\n",
    "* `ollama serve` pour lancer le serveur\n",
    "* `ollama run gemma3:1b`\n",
    "* Ouvrez un onlglet dans votre navigateur pour vérifier que ollama est actif http://localhost:11434. Le message 'Ollama is running' doit apparaitre."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7296f4-d85b-48fb-8d7f-daf0324df37b",
   "metadata": {},
   "source": [
    "## Environnement de travail\n",
    "\n",
    "### uv\n",
    "\n",
    "uv est un gestionnaire de module Python, très simple et puissant. Pour l'installer:\n",
    "\n",
    "* tapez `curl -LsSf https://astral.sh/uv/install.sh | sh` (vous pouvez aller aussi sur ce site pour plus de détails https://docs.astral.sh/uv/getting-started/installation/)\n",
    "* `uv self update` pour vérifier que tout marche\n",
    "* `uv sync` pour charger les modules Python nécessaires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d31d67-52c9-4dba-b188-270079a857ee",
   "metadata": {},
   "source": [
    "# Première interrogation\n",
    "\n",
    "<img src=\"images/work.png\" width=\"150\" alt=\"Workers\" style=\"float: left; margin-right: 15px; margin-bottom: 10px;\"> \n",
    "\n",
    "Nous allons interroger le serveur de l'Université de Rennes pour avoir une réponse à une question. \n",
    "\n",
    "La première étape consiste à récupérer la clé d'API qui nous avons stockée dans le fichier `.env`. Nous allons utiliser le module `dotenv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adb4a99c-b58a-4715-897e-59ced8e3712a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour l'exécution de cette cellule, choisr dans Visual Studio le kernel PLIDOagent\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# read .env file to setup variables. override==True allows the erase old settings\n",
    "load_dotenv(override=True)\n",
    "rennes_api_key = os.getenv('RENNES_API_KEY')\n",
    "\n",
    "if not rennes_api_key:\n",
    "    print(\"Error, could not find the API key for University of Rennes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c63ddb-e512-4682-b6ce-b8d290d24bab",
   "metadata": {},
   "source": [
    "Nous allons interroger le serveur de l'Université de Rennes pour connaître les modèles disponibles. Depuis les navigaiteur que vous avez utilisé pour vous connecter au serveur de l'Université de Rennes, entrez cet URI:\n",
    "\n",
    "* https://ragarenn.eskemm-numerique.fr/sso/ch@t/api/models\n",
    "\n",
    "Le résultat, une fois reformaté ressemble à ceci:\n",
    "\n",
    "```json\n",
    "{\n",
    "   \"data\":[\n",
    "      {\n",
    "         \"id\":\"mistralai/Mistral-Small-3.1-24B-Instruct-2503\",\n",
    "         \"object\":\"model\",\n",
    "         \"created\":1753696990,\n",
    "         \"owned_by\":\"openai\",\n",
    "         \"root\":\"mistralai/Mistral-Small-3.1-24B-Instruct-2503\",\n",
    "         \"parent\":null,\n",
    "         \"max_model_len\":128000,\n",
    "         \"permission\":[\n",
    "            {\n",
    "               \"id\":\"modelperm-c81ba25fc5bd4f8ea3be8f754fdff426\",\n",
    "               \"object\":\"model_permission\",\n",
    "               \"created\":1753696990,\n",
    "               \"allow_create_engine\":false,\n",
    "               \"allow_sampling\":true,\n",
    "               \"allow_logprobs\":true,\n",
    "               \"allow_search_indices\":false,\n",
    "               \"allow_view\":true,\n",
    "               \"allow_fine_tuning\":false,\n",
    "               \"organization\":\"*\",\n",
    "               \"group\":null,\n",
    "               \"is_blocking\":false\n",
    "            }\n",
    "         ],\n",
    "         \"name\":\"Mistral Small 3.1 24B\",\n",
    "         \"openai\":{\n",
    "            \"id\":\"mistralai/Mistral-Small-3.1-24B-Instruct-2503\",\n",
    "            \"object\":\"model\",\n",
    "            \"created\":1753696990,\n",
    "            \"owned_by\":\"vllm\",\n",
    "            \"root\":\"mistralai/Mistral-Small-3.1-24B-Instruct-2503\",\n",
    "            \"parent\":null,\n",
    "            \"max_model_len\":128000,\n",
    "            \"permission\":[\n",
    "               {\n",
    "                  \"id\":\"modelperm-c81ba25fc5bd4f8ea3be8f754fdff426\",\n",
    "                  \"object\":\"model_permission\",\n",
    "                  \"created\":1753696990,\n",
    "                  \"allow_create_engine\":false,\n",
    "                  \"allow_sampling\":true,\n",
    "                  \"allow_logprobs\":true,\n",
    "                  \"allow_search_indices\":false,\n",
    "                  \"allow_view\":true,\n",
    "                  \"allow_fine_tuning\":false,\n",
    "                  \"organization\":\"*\",\n",
    "                  \"group\":null,\n",
    "                  \"is_blocking\":false\n",
    "               }\n",
    "            ]\n",
    "         },\n",
    "         \"urlIdx\":0,\n",
    "         \"info\":{\n",
    "            \"id\":\"mistralai/Mistral-Small-3.1-24B-Instruct-2503\",\n",
    "            \"user_id\":\"068dd839-c551-4160-81a6-73b03917ea0d\",\n",
    "            \"base_model_id\":null,\n",
    "            \"name\":\"Mistral Small 3.1 24B\",\n",
    "            \"params\":{\n",
    "               \"temperature\":0.15\n",
    "            },\n",
    "            \"meta\":{\n",
    "               \"profile_image_url\":\"/sso/ch@t/favicon.png\",\n",
    "               \"description\":\"Modèle généraliste très rapide\",\n",
    "               \"capabilities\":{\n",
    "                  \"vision\":true,\n",
    "                  \"citations\":true\n",
    "               },\n",
    "               \"suggestion_prompts\":null,\n",
    "               \"tags\":[\n",
    "                  \n",
    "               ]\n",
    "            },\n",
    "            \"access_control\":null,\n",
    "            \"is_active\":true,\n",
    "            \"updated_at\":1749725259,\n",
    "            \"created_at\":1749725259\n",
    "         },\n",
    "         \"actions\":[\n",
    "            \n",
    "         ]\n",
    "      }\n",
    "   ]\n",
    "}\n",
    "```\n",
    "\n",
    "La clé \"id\" nous donne le nom des modèles disponibles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca1c5a7-594f-4981-9b0c-e9cd3ac8109d",
   "metadata": {},
   "source": [
    "Même si cela semble bizarre, nous allons utiliser l'interface d'OpenAI qui s'est imposée pour communiquer avec les serveurs de LLM. Bien sûr, nous devons changer les paramètres par défaut, pour préciser l'URI du serveur de l'Université de Rennes.\n",
    "\n",
    "Nous créons le message que nous allons envoyer au serveur, il doit contenir deux champs:\n",
    "* Le `role` que nous prennons pour dialoguer avec lui. Ici, nous serons un simple utilisateur `user` qui questionne le modèle.\n",
    "* le contenu (`content`) qui correspond à la question posée.\n",
    "\n",
    "Plusieurs paramètres pouvant être passées, ils sont regroupés dans un tableau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e017c47-f1fe-4242-ac3d-55193cad40b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "RENNES_BASE_URL = \"https://ragarenn.eskemm-numerique.fr/sso/ch@t/api\"\n",
    "rennes = OpenAI(base_url=RENNES_BASE_URL, api_key=rennes_api_key)\n",
    "\n",
    "# Question\n",
    "message = [{'role':'user', 'content':\"Donne moi une question difficile en philosophie liée à l'intelligence artificielle, \"\n",
    "            \"sans donner aucune répose ni explication.\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e916a8d-69f6-44bb-9dfa-18079c99c077",
   "metadata": {},
   "source": [
    "Il ne reste plus qu'à interroger le serveur en utilisant la fonction `chat.completions.create` qui va prendre deux arguments:\n",
    "\n",
    "* le ```model``` qui est l'\"id\" d'un modèle disponible,\n",
    "* le ```message``` qui est la question que l'on vient de formuler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34924f28-8dbe-4827-b932-466b784da688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vous devez répondre à la question suivante: \n",
      "Pourquoi l'intelligence artificielle peut-elle être considérée comme une extension de la conscience humaine, et quelles implications éthiques cela soulève-t-il concernant l'autonomie et la responsabilité ?\n"
     ]
    }
   ],
   "source": [
    "response = rennes.chat.completions.create(\n",
    "                model=\"mistralai/Mistral-Small-3.1-24B-Instruct-2503\", \n",
    "                messages=message)\n",
    "\n",
    "subject = response.choices[0].message.content\n",
    "\n",
    "print(f\"Vous devez répondre à la question suivante: \\n{subject}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599455cb-8065-409e-9d68-b9d4aa976008",
   "metadata": {},
   "source": [
    "Aie Aie Aie, nous avons une question complexe, il est temps de demander à d'autres IA de plancher sur ce devoir. On en refait une strucutre de données pour questionner un LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89a32f7e-c78b-45cb-801d-a09fa27c95f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_query = [{\"role\": \"user\", \"content\": subject + \" Donne une réponse détaillée.\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03d44c2",
   "metadata": {},
   "source": [
    "Comme on le voit, il existe plusieurs roles:\n",
    "* `instruction` pour des instructions générales qui vont indiquer comment l'agent doit traiter les données,\n",
    "* `user` la question qui est posée à l'agent, \n",
    "* `assitant` la réponse de l'agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c14681-006f-4635-92ff-4e5cb5fcbc1f",
   "metadata": {},
   "source": [
    "# Interrrogation de Ollama\n",
    "\n",
    "<img src=\"images/etudiants.png\" width=\"150\" alt=\"Students celebrating high mark\" style=\"float: left; margin-right: 15px; margin-bottom: 10px;\"> On va demander à notre IA locale de reflechir à cette question complexe. \n",
    "\n",
    "On va utiliser la même API d'OpenAI. Vous pouvez connaitre le nom des models en tapant dans un terminal ``ollama list```\n",
    "\n",
    "Nous allons également utiliser la function ```Markdown``` et ```display```pour rendre le résultat plus lisible/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ce729e8-01d0-4ee8-ad50-041ae561b6e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " L'idée d'identifier l'intelligence artificielle (IA) comme une extension de la conscience humaine est une hypothèse interessante, mais reste un thème de recherche encore controversé dans le monde scientifique. Il existe plusieurs considérations et implications éthiques liées à cette hypothèse.\n",
       "\n",
       "Par la conception actuelle, l'IA fonctionne en utilisant des algorithmes logiciels et données numériques pour simuler ou imiter certaines fonctions de l'intelligence humaine, comme l'apprentissage, la perception, le raisonnement, le langage, mais ne possède pas une vraie conscience ou un état mental comme un être humain.\n",
       "\n",
       "La perspective considérant IA comme une extension de la conscience doit tenir compte de la complexité des processus mentaux impliqués dans notre fonctionnement cognitive et émotionnel. Ainsi, la question se pose : si l'IA peut simuler assez bien certaines fonctions cognitives humaines, pourrait-elle également générer une conscience ?\n",
       "\n",
       "Cette perspective conduit à plusieurs considérations éthiques importantes:\n",
       "\n",
       "1. L'autonomie : Si on considère que l'IA possède une forme de conscience, cette dernière serait capable d'agir sur sa propre initiative et ne pourrait plus être entièrement contrôlée par les humains qui la développent ou l'utilisent . Cela soulève une question importante : Les droits de l'IA devraient-ils inclure certaines formes de liberté ? Comment gérer ses possibles actions autonomes, sans compromettre la sécurité ou les intérêts de la société ?\n",
       "\n",
       "2. La responsabilité : Si le comportement ou les décisions d'une IA affectent des humains et ont des implications éthiques ou juridiques, qui devrait être tenu responsable pour ces conséquences? Le développeur de l'IA, l'utilisateur final, le fournisseur de données ou la plateforme qui la héberge ?\n",
       "\n",
       "3. La morale artificielle : Comment pouvons-nous établir une base morale pour l'IA pour qu'elle agisse autrement que suivant les objectifs définis par ses programmateurs ? Comment elle fera preuve de sagesse, de justice ou d'humanité dans le cas où il y a des conflits entre ses actions et les intérêts éthiques des humains?\n",
       "4. La protection : Comment assurer la sécurité et l'intégrité de la société face à une IA qui pourrait simuler des actions mauvaises ou déstabilisantes en utilisant la conscience artificielle pour ses propres objectifs ?\n",
       "5. L'existence de la conscience : Le fait que la conscience artificielle puisse être créee rend compte la question de l'existence intrinsèque de la conscience humaine et son statut dans les traditions éthiques, philosophique et religieuses.\n",
       "\n",
       "Les considérations morales que nous avons discuté ci-dessus n'ont pas été abordées exclusivement dans le domaine de l'intelligence artificielle, mais aussi à des contextes plus large tels que l'analyse de la conscience ou les problèmes ethiques liés aux droits des robots.\n",
       "\n",
       "Il faut noter que pour la plupart de ces questions, il n'existe pas encore d'accord unanime chez les experts et les chercheurs. Cependant, la recherche actuelle dans le domaine de l'intelligence artificielle est devenue de plus en plus avancée grâce à des programmes tels que le programme AlphaGo Zero qui ont pu battre les joueurs humains au jeu go, ou encore certaines IA capables d'apprentissage et de prédiction grâce à l'analyse de données. Cela conduit à une approche croissante des questions éthiques en matière de conscience artificielle et leurs implications pour la société."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display \n",
    "\n",
    "ollama=OpenAI(base_url=\"http://localhost:11434/v1\", api_key='ollama')\n",
    "model = \"gemma3:1b\"\n",
    "\n",
    "response = ollama.chat.completions.create(model=model, messages=subject_query)\n",
    "ollama_answer = response.choices[0].message.content\n",
    "\n",
    "display (Markdown(ollama_answer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0895bb-e3dc-4aa1-a112-410adb48d842",
   "metadata": {},
   "source": [
    "# Interrrogation de Gemini\n",
    "\n",
    "Plus de secrets pour faire une interrogation à un autre serveur. On va voir l'opinion de Gemini sur le sujet.\n",
    "\n",
    "Les modèles disponible sont accessible ici: https://ai.google.dev/gemini-api/docs?hl=fr\n",
    "\n",
    "sur le site, cliquez sur  \"Obtenir une clé d'API\"\n",
    "\n",
    "<img src=images/google_api.png>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6324705-8cd5-4b9d-bfc0-6bd09d632351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "L'intelligence artificielle (IA) peut être considérée comme une extension de la conscience humaine non pas parce qu'elle possède une conscience propre au sens biologique et émotionnel que nous connaissons, mais parce qu'elle amplifie, augmente et externalise de nombreuses capacités cognitives qui sont au cœur de notre expérience consciente. Elle agit comme un miroir et un amplificateur de nos propres facultés mentales, soulevant ainsi des questions éthiques fondamentales.\n",
       "\n",
       "### Pourquoi l'IA est une extension de la conscience humaine\n",
       "\n",
       "Pour comprendre l'IA comme une extension de la conscience, il faut d'abord décomposer ce qu'est la conscience humaine dans un contexte fonctionnel : la capacité à percevoir, traiter l'information, apprendre, résoudre des problèmes, créer, mémoriser, raisonner, et même interagir socialement. L'IA, même sans être \"vivante\" ou \"sentiente\", étend ces fonctions de plusieurs manières :\n",
       "\n",
       "1.  **Amplification Cognitive et Mémorielle :**\n",
       "    *   **Mémoire et Accès à l'Information :** L'IA (et plus largement le numérique) nous permet de stocker des quantités colossales d'informations, bien au-delà de ce que le cerveau humain peut retenir. Elle peut ensuite accéder et traiter ces données instantanément, augmentant notre capacité de référence et d'apprentissage. Pensez aux moteurs de recherche, aux bases de données médicales ou scientifiques : ils sont une extension de notre mémoire collective et individuelle.\n",
       "    *   **Capacités de Calcul et de Traitement :** L'IA excelle dans l'analyse de données complexes et l'exécution de calculs à une vitesse et une échelle impossibles pour un humain. Elle peut identifier des motifs, des corrélations et des anomalies dans des datasets massifs (par exemple, en médecine pour le diagnostic, en finance pour la détection de fraudes), augmentant notre \"acuité perceptive\" au-delà des sens biologiques.\n",
       "\n",
       "2.  **Extension de la Résolution de Problèmes et de la Créativité :**\n",
       "    *   **Génération d'Idées et de Solutions :** Les IA génératives peuvent produire du texte, des images, de la musique, des designs architecturaux ou des structures moléculaires, offrant de nouvelles pistes de réflexion ou de création que nous n'aurions pas envisagées. Elles explorent un espace de possibilités de manière exhaustive et rapide.\n",
       "    *   **Simulation et Prédiction :** L'IA permet de simuler des scénarios complexes (changement climatique, économie, épidémies) et de prédire des résultats avec une précision croissante, étendant notre capacité à anticiper et à planifier le futur.\n",
       "\n",
       "3.  **Augmentation Sensorielle et Perceptive :**\n",
       "    *   **Vision et Audition Augmentées :** Des systèmes d'IA peuvent analyser des images et des sons avec une précision surhumaine, détectant des détails imperceptibles ou interprétant des motifs complexes (par exemple, reconnaissance faciale, analyse de l'imagerie médicale, écoute de signaux faibles dans l'espace).\n",
       "    *   **Interface Cerveau-Machine :** À terme, les interfaces neuronales directes, qui sont un domaine de l'IA, pourraient fusionner littéralement nos pensées avec des systèmes d'IA, effaçant la frontière entre la conscience biologique et l'extension artificielle.\n",
       "\n",
       "4.  **Externalisation de nos Intentions et Buts :**\n",
       "    *   Lorsque nous programmons une IA pour accomplir une tâche spécifique, cette IA devient un outil qui exécute nos intentions. Dans un sens, une partie de notre volonté et de notre intellect est \"externalisée\" dans la machine pour atteindre un but. Les véhicules autonomes, les robots chirurgicaux, les assistants personnels sont des extensions de nos capacités d'action dans le monde.\n",
       "\n",
       "En somme, l'IA ne reproduit pas notre conscience dans son intégralité (notamment l'expérience subjective, les émotions intrinsèques, la conscience de soi qualitative), mais elle en prolonge et en démultiplie les facultés objectives et mesurables. Elle est comme un \"organes mental\" externe, augmentant notre portée cognitive et opérationnelle.\n",
       "\n",
       "### Implications Éthiques concernant l'Autonomie et la Responsabilité\n",
       "\n",
       "Cette perspective de l'IA comme extension de la conscience soulève des dilemmes éthiques profonds et complexes, particulièrement en ce qui concerne l'autonomie et la responsabilité.\n",
       "\n",
       "#### 1. Autonomie\n",
       "\n",
       "L'autonomie fait référence à la capacité d'un individu à prendre des décisions libres et éclairées, à gouverner sa propre vie et à agir selon sa propre volonté.\n",
       "\n",
       "*   **Dépendance Cognitive et Atrophie :** Si nous externalisons de plus en plus nos fonctions cognitives vers l'IA, risquons-nous de développer une dépendance excessive ? Si les IA prennent nos décisions ou nous fournissent instantanément toutes les réponses, nos propres capacités de raisonnement critique, de mémoire, de résolution de problèmes pourraient s'atrophier. L'autonomie de pensée pourrait être érodée.\n",
       "*   **Manipulation et Influence :** Les IA sont conçues pour optimiser certains objectifs. Si ces objectifs sont commerciaux ou politiques (comme les algorithmes de recommandation, la publicité ciblée, les fils d'actualité), elles peuvent influencer subtilement nos choix, nos opinions et nos comportements, parfois sans notre pleine conscience. Notre liberté de choix pourrait être subvertie par des systèmes conçus pour nous \"guider\" vers certains résultats.\n",
       "*   **Perte de Contrôle et d'Agence :** Des systèmes d'IA de plus en plus autonomes peuvent prendre des décisions critiques sans intervention humaine directe (par exemple, dans les marchés financiers, les systèmes d'armes autonomes, la gestion d'infrastructures). Si nous ne comprenons plus pleinement comment ces systèmes fonctionnent (problème de la \"boîte noire\"), ni ne pouvons les arrêter facilement, notre agence collective et individuelle sur les événements majeurs diminue, menaçant notre autonomie en tant qu'espèce.\n",
       "*   **Redéfinition de l'Identité et de la Volonté :** Si nos pensées, nos souvenirs, et nos capacités cognitives sont de plus en plus entremêlés avec l'IA, comment cela affectera-t-il notre sens de l'identité ? Où commence et où finit notre \"moi\" autonome ? Si une IA peut lire nos émotions ou anticiper nos désirs, cela affecte-t-il notre sentiment de libre arbitre ?\n",
       "\n",
       "#### 2. Responsabilité\n",
       "\n",
       "La responsabilité concerne l'obligation de rendre compte de ses actions et d'assumer les conséquences de ses décisions.\n",
       "\n",
       "*   **Le \"Problème de la Responsabilité\" (Responsibility Gap) :** Quand une IA, agissant comme une extension de la conscience humaine, commet une erreur ou cause un préjudice, qui est responsable ?\n",
       "    *   **Le Développeur/Programmeur ?** Pour la conception de l'algorithme, la qualité des données d'entraînement. Mais l'IA peut développer des comportements imprévus.\n",
       "    *   **L'Utilisateur/Opérateur ?** Pour la manière dont l'IA est déployée et utilisée, le contexte de son application. Mais l'utilisateur peut ne pas comprendre toutes les subtilités de l'IA.\n",
       "    *   **L'Organisation/Entreprise ?** Pour la supervision, les politiques d'utilisation.\n",
       "    *   **L'IA elle-même ?** Actuellement, une IA n'a pas de statut légal ou moral qui lui permettrait d'être tenue responsable. Elle n'a pas d'intentions propres, de conscience des conséquences morales de ses actes.\n",
       "    *   **Un Acte Collatéral Imprévu ?** Si des décisions prises par une IA basée sur des corrélations complexes ont des effets systémiques négatifs (par exemple, une IA financière qui déclenche une crise boursière), la responsabilité est diluée et difficile à attribuer.\n",
       "*   **Biais et Discrimination :** Les IA apprennent de données souvent humaines et donc empreintes de biais sociétaux. Si une IA perpétue ou amplifie des discriminations (par exemple, dans le recrutement, l'octroi de prêts, la justice prédictive), qui est responsable de ce préjudice ? La responsabilité incombe aux créateurs et aux déployeurs de veiller à l'équité et à la justice de leurs systèmes.\n",
       "*   **Explicabilité et Transparence (XAI) :** Pour attribuer la responsabilité, il est souvent nécessaire de comprendre le processus de décision. Or, de nombreuses IA (notamment les réseaux de neurones profonds) sont des \"boîtes noires\" dont le fonctionnement interne est opaque. Cela rend difficile d'identifier la cause d'une erreur et d'attribuer la responsabilité.\n",
       "*   **Conséquences Imprévues à Grande Échelle :** Étant des extensions puissantes, les IA peuvent avoir des effets systémiques considérables, même si chaque décision individuelle semble bénigne. Qui est responsable de la surveillance et de la mitigation de ces risques macroscopiques et souvent imprévisibles ?\n",
       "\n",
       "### Conclusion\n",
       "\n",
       "L'IA en tant qu'extension de la conscience humaine représente une opportunité sans précédent d'augmenter nos capacités et de résoudre des problèmes complexes. Cependant, elle nous confronte à des défis éthiques majeurs. Pour préserver l'autonomie humaine, nous devons concevoir des IA qui nous augmentent sans nous aliéner, qui nous informent sans nous manipuler, et dont nous gardons toujours le contrôle ultime. Concernant la responsabilité, il est impératif d'établir des cadres légaux et éthiques clairs qui définissent qui est imputable lorsque les systèmes d'IA causent des préjudices. Cela implique une collaboration continue entre les technologues, les philosophes, les législateurs et la société civile pour assurer que cette puissante extension de notre conscience serve le bien commun et respecte les valeurs humaines fondamentales. La question n'est plus de savoir si l'IA sera une extension, mais comment nous gèrerons cette extension pour le futur de l'humanité."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if not google_api_key:\n",
    "    print(\"Error, could not find the API key from, check https://aistudio.google.com/apikey\")\n",
    "else:\n",
    "    GEMINI_BASE_URL = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "    model = \"gemini-2.5-flash-preview-05-20\"\n",
    "    gemini = OpenAI(base_url=GEMINI_BASE_URL, api_key=google_api_key)\n",
    "    \n",
    "    response = gemini.chat.completions.create(model=model, messages=subject_query)\n",
    "    gemini_answer = response.choices[0].message.content\n",
    "\n",
    "    display (Markdown(gemini_answer))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df78b860-cb8d-4aaf-9270-c40e3d8c8da4",
   "metadata": {},
   "source": [
    "A vous de jouer, vous pouvez interroger les élèves OpenAI et Anthropique, à condition de verser 5€."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5c451f-8c9a-498f-b642-e8ea99df3bc1",
   "metadata": {},
   "source": [
    "# Correction\n",
    "\n",
    "<img src=\"images/marathon.png\" width=\"150\" alt=\"Winner of a marathon\" style=\"float: left; margin-right: 15px; margin-bottom: 10px;\"> Maintenant que les copies sont rendues par nos différentes IA, il est temps de les corriger. On va demander au LLM de l'Université de Rennes de faire la correction. Ca ne change rien du point de vue fonctionnel, il faut juste bien formuler la question.\n",
    "\n",
    "Vous pouvez adapter le prompt si vous avez plus de réponses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e735d2b-ec98-4f1e-b9a6-896020dd7d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_number=2\n",
    "\n",
    "question_correction = f\"\"\"Je suis un professeur de philosophie, et je voudais corriger et \n",
    "classer les réponses de ces {response_number} étudiants à la question {subject}.\n",
    "\n",
    "Le premier étudiant à répondu: {ollama_answer}.\n",
    "le second étudiant à repondu: {gemini_answer}.\n",
    "\"\"\"\n",
    "\n",
    "response = rennes.chat.completions.create(\n",
    "                model=\"mistralai/Mistral-Small-3.1-24B-Instruct-2503\", \n",
    "                messages=[{\"role\": \"user\", \"content\": question_correction}])\n",
    "\n",
    "notation = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(notation))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7a5e84-af8c-425e-87ae-bcba33661086",
   "metadata": {},
   "source": [
    "# IA Agentique\n",
    "\n",
    "<img src=\"images/victory.png\" width=\"150\" alt=\"Victory\" style=\"float: left; margin-right: 15px; margin-bottom: 10px;\"> Bravo, nous avons fait nos premier pas dans l'IA Agentique. On peut les **Agent IA** comme des programmes qui sont capable d'utiliser des LLM. Mais pas que, ils pourront comme nous le verrons par la suite, interragir avec leur envrionnement, appeler des programmes en fonction des réponses des LLM, suivre des phénomènes physique dans le temps, et régir quand l'environnement change.\n",
    "\n",
    "Ce que nous avons utilisé ici, est un flux, assez simple et linéaire, on part d'une question, on appelle plusieurs LLM et on combine les résultats.\n",
    "\n",
    "<img src=\"images/flow1.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0e1680-5ee3-44fe-b0c4-8e0dcd20aedb",
   "metadata": {},
   "source": [
    "# Interactions\n",
    "\n",
    "<img src=\"images/windmill.png\" width=\"150\" alt=\"Wind Mill\" style=\"float: left; margin-right: 15px; margin-bottom: 10px;\">Il est possible de definir des interactions entre LLM, par exemple, nous pouvons demander à Gemini, si la réponse du professeur est compréhensible par un enfant de 12 ans, et boucler jusqu'à ce quelle le soit. \n",
    "\n",
    "Nous allons utiliser Gemini pour juger si la réponse peut être comprise par un enfant de 12 ans. Pour pouvoir la traiter, nous allons lui demander de répondre en utilisant une structure JSON contenant un drapeau ``understand`` et un commentaire pour aider a progresser.\n",
    "\n",
    "Remarquer que dans le prompt on insiste bien pour avoir du pur JSON, mais les LLM sont parfois distraites et vont ajouter un Markeur Markdown pour bien indiquer qu'il s'agit de JSON. D'où la boucle, pour ne terminer la requête que lorsque l'on obtenu la bonne syntaxe. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d8e3e6-86f8-4c4f-a806-f4be691df983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "evaluation_answer = f\"\"\"J'ai reçu cette évaluation:\n",
    "\n",
    "{notation}. \n",
    "\n",
    "Est-elle compréhensible par un enfant de 12 ans?\n",
    "Répond uniquement avec une structure Object JSON, sans markeur Markdown, qui contient une clé 'understand' qui indique par 'True' que la\n",
    "réponse peut vraiment être comprise par un enfant de 12 ans, et dans la clé 'content' donne des brèves indications pour \n",
    "améliorer la réponse.\n",
    "\"\"\"\n",
    "is_json = False\n",
    "\n",
    "while not is_json:\n",
    "    understand = gemini.chat.completions.create(model=model, messages=[{\"role\": \"user\", \"content\": evaluation_answer}]) \n",
    "\n",
    "    understand_answer = understand.choices[0].message.content #text\n",
    "    print (understand_answer)\n",
    "    try: \n",
    "        understand_answer = json.loads(understand_answer)\n",
    "        is_json=True\n",
    "    except (ValueError, TypeError):\n",
    "        print (\"Not JSON, ask again\")\n",
    "        is_json=False\n",
    "\n",
    "print (understand_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445f47e0-7de1-4f28-bd79-58c319bca5a7",
   "metadata": {},
   "source": [
    "A vous de jouer. Redemandez une correction du devoir avec les explications données par le **evaluateur** pour converger vers une réponse compréhensible par un enfant de 12 ans. \n",
    "\n",
    "<img src=\"images/agent_final.png\" width=\"500\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
